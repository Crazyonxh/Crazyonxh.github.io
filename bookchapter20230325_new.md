Real-time Ultra-large-Scale imaging with High-resolution microcopy

Qionghai Dai

Department of Automation, Tsinghua University

Abstract

This chapter presents a novel microscopy technique, Real-time Ultra-large Scale imaging with High resolution microscopy (RUSH), which enables imaging of biological systems with unprecedented space–bandwidth product and data throughput. We describe the design and implementation of the RUSH system, which comprises a customized objective lens, a camera array, and a computer cluster. We also demonstrates the applications of the RUSH system in imaging neural activity in mouse brains and other biological samples with curved surfaces. Further, we introduces algorithms for image denoising and neural detection, and discusses the challenges and opportunities for large-scale imaging. The chapter aims to provide readers with an overview of the RUSH system and its potential for advancing system biology studies

1.  Introduction

Due to the intricate and constantly changing nature of living systems, predicting systematic behaviors solely from the properties of individual components is often challenging. To investigate the biology of a system, such as neural network activity across cortical regions, leucocyte trafficking dynamics, or tumor metastasis, an appropriate microscope is required, which possesses a field of view (FOV) of at least one millimeter, sub-cellular resolution, and the ability to record biological processes in real-time.

However, there are some fundamental challenges to achieve such a system:

-   An optical system with high space–bandwidth product (SBP), i.e., a combination of high resolution and FOV.
-   An acquisition system that has high data throughput, i.e., a large pixel number and frame rate.
-   A data transfer and storage system that can have the capacity for high data throughput
-   A large depth of field to deal with the curvature of the mouse brain
-   A denoise algorithm that can enhance the signal to noise level of images
-   A calcium extraction algorithm that can efficiently extract calcium signal with high speed and accuracy

This chapter is structured into six sections. The first section serves as an introduction to the topic. The second section presents the Real-time Ultra-large Scale imaging with High resolution microscopy (RUSH) approach, which involves using a customized microscope and a camera array to achieve ultra-large scale and high resolution imaging. The third section describes the attempt to simultaneously monitor neural activity in the superficial cortex and hippocampus. In the fourth section, meso-scale imaging is extended to a curved surface. The fifth and sixth sections introduce algorithms for image denoising and neural detection, respectively. Finally, the limitations and future directions for large-scale imaging are discussed.

1.  Real-time Ultra-large Scale imaging with High resolution microcopy (RUSH)

The SBP of microscopes is fundamentally restricted by scale-dependent geometric aberrations of optical systems, leading to a compromise between achievable resolution and FOV. To overcome this limitation, two approaches have been developed: (1) image stitching, in which large samples are imaged in pieces, and (2) Fourier ptychography, in which the specimen is imaged under various illumination conditions with a low-resolution system, and the final image is obtained via Fourier-domain post-processing. Unfortunately, these techniques suffer from low speed and are incapable of supporting single-shot, whole-FOV information acquisition, which is essential for imaging biological dynamics. Additionally, these methods require the samples to remain static during the entire imaging process, making them challenging to apply to in vivo imaging of awake, behaving animals. Furthermore, the need to select small regions of interest (ROIs) for high-speed recording renders their application impossible for large-scale imaging of biological dynamics.

2.1 System Setup

**Optical Design.** To address the above challenges, we have proposed the Real-time Ultra-large Scale imaging with High resolution microcopy (RUSH). The customized objective used in the RUSH system was composed of 14 optical elements in 11 groups, and was 161 mm in diameter and 280 mm in length. It was designed to achieve a 10 mm × 12 mm FOV and 0.35 NA over the wavelength range 420–680 nm. The entire optical system had a magnification factor of ×8 and an off-axis and spacing tolerance of \~2 μm. For wide-field fluorescence imaging, a light-emitting diode light source was used for excitation, with a bandpass excitation filter at 470 ± 20 nm and an emission filter at 525 ± 20 nm, chosen based on the fluorescence dyes or proteins used in the imaging. Supplementary Fig. 1 provides more details on the technical specifications.

In fluorescence imaging mode, the excitation beam from the light source is filtered with an excitation filter and reflected by the dichroic mirror (DM), before it passes through the customized objective and is projected onto biological samples. The fluorescence is collected by the same objective, filtered by the DM and an emission filter, reflected by a mirror (M), and forms a spherical intermediate image. The spherical field is divided into 5 × 7 sub-FOVs and imaged with corresponding collection units composed of the relay lens array and 35 water-cooled sCMOS cameras with 2,560 × 2,160 pixels and 16-bit depth. The customized objective lens is designed with 0.35 NA and 10 × 12 mm2 FOV; the collection units provide a data throughput of up to 5.1 gigapixels per second.

**Image Stitching.** The alignment of sub-FOVs is crucial for seamless stitching and requires high-accuracy calibration. However, conventional camera-array calibration techniques fail for RUSH due to its small overlap and shallow depth of field. To overcome this, the authors proposed a fast computation-in-loop calibration approach using spatiotemporal structured illumination to build homographic matrices that map images from 35 cameras to the 10 × 12 mm2 FOV. This approach provides sub-pixel calibration precision and feedback for mounting the camera array. During mounting, the displacement between the captured and expected mappings is calculated, and mounting parameters are fine-tuned accordingly. The proposed approach is computationally efficient and can elegantly address the challenges of assembly and calibration.

STEP 1: We set the global physical coordinates using the temporal-division coding of different cells on a high-density LCD module (\~500 PPI). Specifically, 12-bit temporal codes are used for x and y coordinates, respectively. STEP 2: Each sub-FOV camera captures an image sequence of one specific small LCD region. Then the corresponding global position of each LCD cell can be decoded from its temporal pattern. STEP 3: For each cell in the sub-FOV image, we further extract its precise local image coordinates using centre-of-area method, including binarization and weighted averaging. STEP 4: After retrieving the global and local coordinates of all the sub-FOVs, we build a set of homographic matrices for successive stitching.

**Data Transfer and Storage.** We have designed a computer cluster with nine nodes to handle the large amount of data generated by the RUSH system. The data from the 35 cameras were captured synchronously and continuously with a maximum frame rate of 30 frames per second. The data were then transmitted via dual-camera links to optical cables, with a bandwidth of 5.1 gigapixels per second. The system used a distributed file system with 324 hard disks to schedule local data writing requests to each node and to provide cross-node data exchange capability. This facilitated a highly parallel distributed stitching algorithm with adjustable granularity, which allowed real-time online stitching with adaptive resolution adjustment according to the regions of interest. The entire gigapixel video could be stitched and stored offline at up to 1.1 frames per second. A graphical user interface was developed to provide online flexible visualization of the multi-scale data with two high-definition displays.

We use a root server to control the cameras, the computing cluster, the user client and other external devices including the synchronizer, light source, 3-axis stage, calibrator, and the monitor. Firstly, 35 cameras are synchronized to capture the sub-FOV images based on our customized protocol. The high-bandwidth data is then transmitted through a DFS for data processing. Parallel stitching algorithm is conducted based on the calibrated homographic matrices for real-time display. Users can specify the parameters such as exposure time and illumination intensity by the user control client.

1.  Imaging results

**Ex vivo Cellular Imaging.** In order to demonstrate the efficacy of our RUSH macroscope for large-scale, high-resolution and high-throughput imaging of biological dynamics, we conducted functional imaging of large cell ensembles. While fluorescence imaging of the cardiac cellular network is essential for gaining detailed insights into the cellular processes that are fundamental to cardiac function, it has previously been limited to small fields of view (FOVs) or low resolution23. We cultivated rat primary cardiomyocytes and captured intercellular calcium dynamics at a rate of 30 Hz. Figure 2a presents the spatiotemporal propagation of a calcium wave across the cardiac cell ensemble, with wave phases depicted using different colors that correspond to different temporal delays. Enlarged views of sub-cellular structures are presented in Fig. 2b and c. Furthermore, we show the fluorescence signals (ΔF/F0) of all segmented cells in Fig. 2d, indexed by their wave phases. It can be observed that the calcium signal propagates in a periodically spiral pattern across the entire FOV (Supplementary Video 1). The RUSH system's high throughput allows us to capture non-periodical signal propagation in cardiac ensembles, either within a single cell or among multiple cells (Supplementary Fig. 16 and Supplementary Video 2). However, it is impossible to visualize wave propagation at subcellular resolution with conventional microscopes that have small FOVs.

Compared to cardiac cellular ensembles, neural ensembles have the ability to form long-range connections. As a result, high-resolution and large-scale functional imaging is necessary to study neural network activity effectively. In this regard, we conducted a proof-of-concept experiment using cultured rat neuron ensembles by performing calcium imaging, which was prepared in a manner similar to the cardiac cells. Figure 2e depicts the spatiotemporal alterations of calcium signals across the neuron ensemble, while Fig. 2f–i illustrate the propagation of calcium signals along dendrites. Our RUSH macroscope enables the recording of fluorescence dynamics in somas and the observation of signal propagation along fine structures, such as single dendrites, as illustrated in Supplementary Video 3.

**In vivo Cellular Imaging.** We performed the craniotomy as described in a previous report41, with a window size of \~8 mm × 8 mm, then installed flat optical windows and cemented the custom-made coverslips (D-shape) and aluminum head posts to the skulls.

For acute imaging, Cx3Cr1-GFP transgenic mice (JAX no. 008451) were head-fixed under the RUSH objective for immediate imaging while keeping the mice warm and anaesthetized (1–1.5% isoflurane). For the data shown in Fig. 4, the imaging parameters were 8 b.p.p. and 5 f.p.s. During imaging, awake mice were placed in a tube with their heads restrained under the objective of the RUSH. During imaging with GP4.3 mice, puffs of compressed air (100 ms duration and 10 s interval) were applied to whiskers on the right through a 1-mm-diameter tube placed ∼10 mm away42. For calcium imaging of dendrites, we sparsely labelled the neurons42 of adult C57BL/6 mice with a mixture of diluted AAV2-9-hSyn-cre and AAV2-9-Ef1a-DIO-GCaMP6f viruses (from BrainVTA Technology). For the data shown in Fig. 5, the imaging parameters were 16 b.p.p. and 14 f.p.s.

To showcase the proficiency of the RUSH macroscope in large-scale, high-resolution, and high-throughput imaging of biological dynamics, we performed calcium imaging of neurons and dendrites in awake mice in vivo. In this study, we utilized both virus-infected adult C57BL/6 mice and Thy1-GCaMP6s transgenic mice. Calcium dynamics were recorded at 14 f.p.s., and the results are presented in Fig. 6, Supplementary Figs. 20 and 21, and Supplementary Video 8. Our experiments enabled us to record calcium signals from neural somas (Fig. 6b–e), as well as to observe calcium propagation along dendrites (Fig. 6f–h). These investigations can provide the multi-scale data necessary for studying brain-wide correlations among neuron responses, including the response delay of calcium signals at different branches of a single neuron.

1.  Form flat imaging to multi-planar imaging

As the increase of observed diameter of the mouse brain, curvature of the brain has to become a crucial issue that need to be considered. The edge of the FOV can be hundreds of micrometers to millimeters lower than the central part. Further, recent research has shown that many cognitive processes involve the interaction of multiple brain regions. For instance, the formation of episodic memory is dependent on the interplay between the hippocampus and prefrontal cortex [1-3], while spatial navigation is dominated by hippocampal-parietal cortical interactions [4-7]. Similarly, posttraumatic stress disorder (PTSD) is associated with the amygdala, medial prefrontal cortex, and hippocampus [8]. These nuclei are located more than 1 millimeter beneath the dura in adult mice and are spread across the whole brain. To investigate the dynamic behavior of different brain modules at a fine scale, it is essential to have an optical system with cellular resolution, brain-wide field of view, video-rate acquisition, and multi-depth imaging capabilities.

In this section, we firstly introduce a novel wide-field fluorescence microscope called the Spinning-disk Mesoscopic ARbitrarily-shaped-surface imaging Technique (SMART). This microscope has the ability to image on non-planar surfaces while maintaining high spatial resolution across a large field of view. To achieve this, we have developed an active imaging framework that includes automatic detection of the surface profile, active control of illumination, high-speed spinning-disk scanning, and multiplexed detection. The use of a spinning disk and high-speed cameras, similar to the RUSH system and micro-camera array microscope, provides SMART with high optical throughput, enabling it to scan 16.8 voxels per second. In the second part, we introduce an endoscopic method, which address the challenge of simultaneous recording of the cortex and hippocampus dynamics with cellular resolution.

3.1 system setup

**SMART.** The operation of SMART is based on a combination of computer vision and optical design, enabling high-resolution imaging of dynamic processes on arbitrarily-shaped surfaces. The imaging process begins with the estimation of surface profiles, which is used to design a spatial-temporal selective illumination sequence. This sequence is then applied to the sample, while the spinning disk is used for fast axial scanning within a single frame exposure time. This allows for the acquisition of surface features with depth encoding. The obtained images, along with the illumination sequence, are then processed to decode cellular information with high accuracy. Overall, this approach provides an effective means for achieving high-resolution imaging of dynamics on complex surfaces.

To address the resolution-depth of field trade-off in SMART microscopy, we implemented a technique in which the focal length is scanned in a single exposure time. To achieve fast and continuous focus shifting, we utilized a spinning disk, which is typically challenging in mesoscopic systems. To enable high-resolution imaging with a large field of view during disk rotation, we replaced traditional lenses with flat optics to change the position of the focal plane. The spinning disk, composed of glasses with varying thicknesses, was positioned between the two surfaces to produce a focus shift, similar to the "broken pencil illusion" in physics. The use of flat optical elements ensures that all regions of the field of view are treated equally, allowing for high-resolution focal length changes across the entire field of view.

To address technical limitations in data transfer speed, we utilized a temporal multiplexing detection method in our imaging approach. Specifically, we employed a digital micromirror device (DMD) to modulate the spatiotemporal illumination of the sample, resulting in brightness only in regions where features were in focus. Additionally, the rotation of the spinning disk was tracked by an infrared detector and recorded by a data acquisition device (DAQ), which was synchronized with the DMD and camera. Through the integration of these innovative techniques, we have successfully overcome technical challenges and achieved high-quality, high-resolution imaging of dynamic processes occurring on complex surfaces.

The illumination patterns were then used to modulate the illumination of the sample through the DMD, which enabled the bright regions to correspond to in-focus areas. The spinning disk was synchronized with the DMD and camera, and the acquisition of images was done in a single frame exposure time. The captured images were then processed to decode cellular information with high accuracy. The axial positions of the surface were also extracted from the illumination patterns and used to reconstruct the surface profile. This approach allows for continuous tuning of the focal depth over a maximum range of \~2 mm and a maximum speed of 140 fps, enabling high-resolution imaging of dynamics on complex surfaces in real time.

**Hippocampal imaging.** Fig. 1(a) and Fig. 1(b) show the principle of simultaneous multi-planar imaging. First, the skull of the mice is removed, and a part of cortical matter is ablated to expose the hippocampus. The surface of the hippocampus is about 1 millimeter below the dura, while the layer 2/3 neurons in the cortex are about 100\~300 μm below the dura. To shift the neurons in the hippocampus to the superficial cortex, media with a higher refractive index is inserted above the hippocampus. The apparent depth Ha in refractive media is related to the real depth Hr according to Snell’s Law, where ni is the refractive index of the imaging plane and no is the refractive index of the refractive media. To compensate for the depth difference, the height of the media that needs to be inserted is calculated as Hm = (no - ni) \* Hr / ni. Assuming a dry objective is used for detection at a wavelength of around 515 nm, the refractive indices are estimated as ni = 1 and no = 1.5. The depth between the hippocampus and superficial cortex is about 0.9 mm, and the thickness of the coverslip is 0.17 mm. Therefore, a customized optical window is designed for multi-planar imaging. A 0.9-mm-height and 2-mm-diameter glass column is stuck to the bottom of the cover glass at the position of the mouse hippocampus, and a second glass column with an optimal thickness of 1.8 mm is placed on the top to further compensate for the depth difference.

During the chronic craniotomy procedure, a 6 mm diameter window was created, and the cortex matter was aspirated using a 0.9 mm diameter blunt needle connected to a vacuum pump. The central position of the ablated cortex was located approximately 1.5 mm from the sagittal suture and 2 mm from the lambdoid suture. Once the cortex matter was aspirated, a chronic window was assembled by adhering a ϕ9 mm glass coverslip to a glass column using tissue adhesive. The window was then implanted above the mouse cortex, and an aluminum head post was mounted to the skull and fixed with dental cement. During the surgery, the mouse was anesthetized with isoflurane, and a breathing frequency of 1 Hz was maintained. Body temperature was kept at 37.5 ℃, and eye ointment was applied. The mouse was allowed to recover for two weeks before chronic imaging experiments were performed. The mouse was alive for more than two months after being implanted with the chronic window

1.  Imaging results

**SMART.** This ability to image the entire superficial brain allowed us to study the spatiotemporal dynamics of neural activity across a large field of view, which is important for understanding the mechanisms underlying brain function. We were able to detect calcium signals from neurons across the mouse cortex in response to visual stimulation, as shown in Figure 2d and Supplementary Video 2. This demonstrates the ability of SMART microscopy to provide high-quality, high-resolution images of neural activity in vivo, which is essential for advancing our understanding of brain function and disease.

The SMART microscopy approach enabled the acquisition of high-resolution images of neural activity with a large field of view and high imaging speed. This allowed for the detection of fast, micrometer-resolution spontaneous activity over the superficial dorsal cortex of the mouse brain, which was difficult to achieve with existing wide-field techniques. By using morphological methods, the time series of images at each depth were used to detect the three-dimensional positions of neurons. A polynomial function was then applied to fit the surface, as shown in the inset of Figure 3a. The resulting images and surface profile provided a comprehensive view of the neural activity across the superficial layer of the cortex.

SMART's ability to capture an image of the entire superficial cortex in one snapshot and identify thousands of neurons with high resolution and efficiency represents a significant advance over existing wide-field techniques. By detecting 5,400 neurons using the CNMF-E algorithm, SMART was able to evenly distribute neurons across the entire field of view, outperforming a conventional microscope with 0.3 NA that could only detect 1,000 neurons within its depth of field. Additionally, by zooming in on four selected regions in detail, SMART was able to reveal the contours of all somata at high resolution, achieving single-cell resolution that surpasses the COSMOS microscope. While the imaging speed of SMART was currently limited by the sCMOS camera speed of up to 50 frames per second, setting the speed to 10 Hz allowed it to match the dynamics of the calcium indicator.

**Hippocampal imaging.** We have demonstrated the capability of our system to perform in-vivo multi-planar neuron imaging in Thy1-YFP mice (JAX No. 003782). The entire mouse brain was imaged using the RUSH microscope, as depicted in Fig. 4(a). The hippocampus and cortex were labeled in Fig. 4(a) and subsequently imaged in Fig. 4(b) and (c), where a number of spine-like structures were clearly distinguished and marked with yellow circles. Additionally, the axons were distinguishable in both subregions, indicated by red arrows, thus highlighting the superior performance of our system. The lateral resolution of our customized microscope, as illustrated in Fig. 5(a), was found to be approximately 3.25 μm, which was restricted by the pixel size of the sCMOS detector. Consequently, only the soma could be visualized in each subregion (Fig. 5(b) and (c)), with a significantly lower signal-to-background ratio. Our results collectively demonstrate that our system has the potential to be employed for in-vivo calcium imaging with cellular resolution.

To assess the viability of our technology for chronic mouse imaging, we allowed a recovery period of two weeks following optical window implantation. In Fig. 7(a1)-7(a3), we present brain images of Thy1-YFP mice captured on Day 14, 30, and 60 post-implantation. Neurons in all regions, including the hippocampus in Fig. 7(b1)-(b3) and superficial cortex in Fig. 7(c1)-(c3), are visible, indicating that our microwindow implantation approach is suitable for chronic imaging. Fig. 7(a1)-(c1) and Fig. 7(a3)-(c3) were captured using the customized-built wide-field fluorescence mesoscope, whereas Fig. 7(a2)-(c2) were captured using the RUSH macroscope. The post-surgery behaviors of the mice (n≥3) were evaluated, and no discernible abnormalities were observed.

1.  Denoising

Fluorescence imaging is photon limited, which means that it is usually not possible to collect enough fluorescent photons to obtain a satisfactory imaging signal-to-noise ratio (SNR). The problem of low imaging sensitivity is the fundamental challenge of fluorescence imaging. Considering the whole process of fluorescence labeling, excitation, and detection, the causes of the photon-limited challenge can be summarized into four aspects (Fig. 1). First, the low quantum yield (i.e., the percentage of photons absorbed by the fluorophore that is converted to fluorescent photons) of fluorescent indicators and their low concentration in labeled cells lead to the short of fluorescent photons at the source. Second, although using higher excitation power can directly increase the number of fluorescent photons (e.g., single-photon fluorescence increases linearly with excitation power, while two- and three-photon fluorescence increases squarely and cubically, respectively), fragile living systems cannot tolerate high excitation power for a long time. Many experiments have shown that light-induced photobleaching, phototoxicity, and tissue thermal damage will disturb normal cellular physiological processes, such as cell proliferation, cell migration, vesicle release, action potential firing, etc. Enhancing imaging SNR by increasing the excitation power is not feasible in practical imaging experiments. Third, observation of high-speed dynamic life activities requires high imaging speed. At a certain number of fluorescent photons emitted by the sample per unit period of time, the higher the imaging frame rate, the shorter the exposure time of each image frame, and the fewer fluorescent photons can be collected. Therefore, high-speed imaging further exacerbates the shortage of fluorescent photons. The last and the most essential reason is the quantum nature of light makes the randomness of optical measurements inevitable. The number of photons detected by even the most sophisticated photodetector can only be a Poisson random number of the actual number of photons. The detection noise due to the quantum nature of light is called photon shot noise. In fluorescence imaging, detection noise dominated by photon noise exacerbates the measurement uncertainty, hinders visualization of the structure and function of living organisms, and can even mislead qualitative and quantitative descriptions of biological mechanisms.

The inherent photon shot noise is the essential cause of the low imaging sensitivity and is also one of the most fundamental and formidable challenges in fluorescence imaging. Fundamentally, all measurement processes obey the laws of quantum mechanics, and the most direct manifestation is the existence of an upper limit on the sensitivity of any measurement. The sensitivity limit of optical measurements in classical physics is known as the photon noise limit (or the well-known standard quantum limit). Fluorescence imaging is a branch of optical measurement technology, and any imaging system based on classical physics is bound to obtain images that are at least Poisson random samples of the actual photon distribution. In theory, the shot-noise limit specifies an upper bound on the imaging SNR. In practice, the inherent photon noise increases measurement uncertainty, degrades image quality, and limits all aspects of imaging performance such as resolution, speed, and depth. Actually, not only fluorescence imaging but any other precision optical measurement is plagued by noise. Photon shot noise is an inescapable obstacle in cutting-edge scientific observations. Nature, one of the most famous international academic journals, published a technical comment in 2021 with a topic of "A shout-out for noise-reduction tools", pointing out that any experimentally measured image contains noise, and calling for the development of more accurate, reliable, and efficient noise suppression tool to facilitate fundamental scientific research.

The information obtained by fluorescence imaging is organized in the form of images, so a natural idea to improve imaging sensitivity is to remove noise in fluorescence images by post-processing, which further reduce the negative impact of noise on downstream analysis. Intelligent image processing methods based on deep learning are the most widely used and best performing solution for image denoising. Using deep learning to restore fluorescence images can compensate for the innate deficiencies of imaging systems and effectively improve microscopic image quality. The application of deep learning consists of two steps. Firstly, data is collected to make a training set, and deep neural networks are trained on the dataset using back-propagation and gradient descent algorithms. Then pre-trained models are deployed and used to process unseen data. Those well-trained models still maintain good generalization on new test data. Such s data-driven paradigm dictates the strong data-dependent nature of deep-learning-based methods, where the dataset has a much greater impact on the performance than the network architecture. Thus, making a representative and category-balanced dataset is crucial for these methods. If a certain class of data is missing in the training set, the network would lose the ability to process such kind of data. Forced processing will often lead to wrong results.

Conventional deep-learning-based denoising methods for fluorescence imaging are based on supervised learning, which means that the training of the deep neural network relies on the supervision of paired ground-truth images (i.e., clean images without noise contamination or high-SNR images with the same underlying scene as the low-SNR images). For static samples, it is not difficult to obtain the ground-truth images by extending the exposure time of the camera or taking many consecutive frames and then calculating the average value of them. So supervised denoising methods are mainly feasible for static or very slowly changing samples. However, biological phenomena are often highly dynamic, non-repetitive activities where the same scene cannot be captured twice, and schemes to obtain training truth values by extending the exposure time or averaging multiple frames are no longer feasible. The heavy reliance on training truth is the most important drawback of conventional supervised methods, but the lack of ground-truth images is very common in fluorescence imaging of living organisms, such as neural calcium imaging, membrane voltage imaging, cell interaction, organelle dynamics, immune response, hemodynamic processes, etc. There is an urgent demand to develop new denoising methods to break the dependence of supervised denoising on truth values.

4.1 Methods

We proposed a self-supervised framework for fluorescence imaging denoising named DeepCAD, which can be used to train denoising models without requiring any ground-truth images and can achieve performance as good as the latest supervised denoising methods. The principle of DeepCAD is shown in Fig.2. The original low-SNR image stack acquired by the imaging system is split into two sub-sequences (xy-t image sequences) of odd and even frames, which are used as the input and target of the deep neural network, respectively. Then, the neural network is trained with stochastic gradient descent. In brief, traditional supervised learning methods use ground-truth images as the supervised data, while DeepCAD uses adjacent frames of the input noisy images as the supervised data. Although the supervised data also contains the same kind of noise as the input data, the network parameters can still converge to values similar to those trained by supervised learning. The proposed DeepCAD was inspired by Noise2Noise. The training mechanism can be explained as follows: noisy target images produce noisy gradients, but the angle between them and the true gradient is still acute (pointing to similar directions). Also, the disturbance of noise can be eliminated after averaging a large number of noisy gradients over the whole training set. Therefore, the final convergence direction of the network is not affected. After training, the parameters of the pre-trained denoised network will be stored in a model file. When new low-SNR data arrives, a three-dimensional (xy-t) window will traverse the whole video and input these data blocks into the pre-trained model. The output of the model is corresponding denoised blocks, and the complete denoised results will be obtained after stitching these output blocks together.

1.  Results

We first captured the spontaneous calcium activity of densely distributed neurites in the first layer of the mouse cerebral cortex using a two-photon microscope. The noise in the original low-SNR images is so severe that it almost drowns out the true signal and the morphology and distribution of dendrites and axons were difficult to recognize (Fig. 3a). After denoising with DeepCAD, those imperceptible fluorescence signals in the original low SNR data can be effectively restored (Fig. 3b). The SNR of the denoised image exceeds that of the high-SNR image with 10-fold fluorescence photons (Fig. 3c), allowing the structure of dendrites and axons to be accurately identified from a single frame. Then, we randomly selected 40 pixels located on the neurites and extracted the fluorescence traces of these pixels, normalized and visualized them in Fig. 3d. After comparing with the corresponding high-SNR data, it can be found that the denoised data can resolve the calcium activity of neurons faithfully. Similarly, we performed calcium imaging data of large neuronal populations in Layer 2/3 of the mouse cerebral cortex. The original low-SNR images and denoised images are shown in Fig. 3e and 3f, respectively. The corresponding high-SNR data with 10-fold photons is shown in Fig. 3g. With the powerful denoising capability of DeepCAD, the fluorescence signal severely disturbed by noise can be recovered. In the denoised image, the structure of neuronal cytoplasm and fibers becomes clearly visible. The spatial distribution and firing state of most neurons can be recognized from a single frame. Magnified views of red-boxed regions are shown at the bottom of each image, which shows that the fluorescence dynamics of different neuronal structures are also effectively recovered.

Furthermore, to meet the growing demand of large-scale image processing and real-time high-sensitivity observation, we comprehensively optimized DeepCAD to improve its processing speed and performance. We also designed a multithreaded processing pipeline, as well as an optimal hardware deployment scheme, to integrate the proposed denoising into the imaging system. We finally implemented real-time noise suppression on a two-photon fluorescence microscope for high-sensitivity imaging. With this high-sensitivity imaging technique, we observed various biological events, including neural calcium activity in multiple model organisms (Drosophila, zebrafish， and mice), the 3D migration of immune cells after acute brain injury, and the 3D dynamics of adenosine triphosphate (ATP) release in the mouse cortex after laser-induced injury. The implementation of real-time high-sensitivity fluorescence imaging will help biologists solve the photon-limited challenge in fluorescence imaging and facilitate the revelation of underlying biological mechanisms in a wide range of applications.

1.  Rapid calcium signal extraction

The use of widefield microscopy has enabled the imaging of multi-millimeter fields of view and thousands of neurons in mammalian brains at a video rate. However, extracting neuronal activity signals from calcium imaging data at a cellular resolution has been a challenge due to the contamination by tissue scattering and background signals, which makes it time-consuming and difficult to accomplish. To address this issue, we propose a deep learning approach called DeepWonder, which is fueled by simulated calcium recordings but effectively works on experimental data. The proposed method achieves an order of magnitude faster processing speed and improved inference accuracy compared to traditional approaches. The DeepWonder algorithm demonstrated a significant improvement in the signal-to-background ratio, achieving a fifty-fold enhancement when processing terabytes-scale cortex-wide recordings. In just 17 hours using workstation-grade computing resources, DeepWonder extracted over 14,000 neurons, which is an impressive feat compared to the nearly week-long processing time with previous methods. This new approach can serve as a guideline for massive data processing in widefield neuronal imaging, circumventing the need for numerous computational resources.

1.  Methods

In this study, we introduce a fast and efficient technique for extracting and demixing neurons from widefield microscope data using deep learning. To overcome the challenge of the lack of training data, we used a simulation of brain tissue to generate optical system-specific paired virtual recordings with and without background. By training a neural network to separate neuronal signals from scattered background, we were able to quickly segment neurons and retrieve spatial footprints and temporal signals using a lightweight convolutional neural network. This technique, which we refer to as DeepWonder, demonstrated nearly tenfold processing speed improvement compared to the widely used CNMF-E algorithm, as validated using both simulation and experimental data. We also verified the accuracy of background removal and segmentation using TPLSM recordings and deployed DeepWonder on several widefield calcium recording systems. Finally, we made our method easily accessible and reproducible by packaging it into a python package and distributing it on an online platform.

The effectiveness of widefield microscope in detecting neurons is limited by background contamination, which hinders signal extraction and detection quality. In DeepWonder, we use a neural network to map images with background contamination to background-free data by generating synthetic widefield calcium imaging data. We create synthetic data by modeling vessels, neurons, and background dendrites and axons based on a specific widefield microscope model to produce realistic virtual recordings with accurate pixel, ΔF/F, and spatial frequency distributions. Paired virtual recordings are fed to the removing background network (RB-Net) to learn the mapping between contaminated and background-free captures. Trained RB-Net learns interpretable features and outputs high-contrast images and vivid neuronal activities without contaminations. DeepWonder enhances correlation scores to the ground truth signals and signal-to-background ratios significantly compared to raw data. RB-Net-driven by virtual data in DeepWonder is effectively applied to remove backgrounds of real recordings. The RB-Net achieves superior performance in SBR, correlation score, and neuron finding scores compared to other state-of-the-art background removal methods while spending almost 7-fold shorter time in removing background. The similarity between virtual generations and real recordings guarantees the high effectiveness of RB-Net in real recordings. We illustrate an SBR improvement in real recordings by RB-Net compared to raw data across 1543 neurons.

NS-Net, the neuron segmentation network proposed in DeepWonder, is designed to segment neurons from background removed data. The NS-Net employs a lightweight CNN that segments neurons from the output of the RB-Net at high speed. The network then semantically segments roughly isolated neurons based on their spatio-temporal connectivity and yields mostly exclusive segmentations. This approach enables the direct readout of the temporal activities of individual neurons since there is no inter-neuron crosstalk. Neurons that are tiled and overlapped are further demixed by a local nonnegative matrix factorization (NMF) algorithm, which eliminates activity crosstalk. NS-Net reliably demixes neurons as close as 0.3 of the neuron diameter, resulting in a temporal similarity of over 0.9 and a spatial similarity of over 0.85.

1.  Results

In terms of performance, NS-Net outperforms state-of-the-art two-photon segmentation techniques CNMF and SUNS with the highest sensitivity and F1 score (0.933 and 0.917, respectively) in the background removed dataset. The processing speed of NS-Net is also 5 times faster than CNMF and comparable to SUNS.

DeepWonder is a framework for analyzing widefield calcium imaging data that achieves a significant improvement in processing speed and accuracy over existing techniques. The framework consists of two neural networks: the Removing Background Network (RB-Net) and the Neuron Segmentation Network (NS-Net). RB-Net removes background contaminations from the imaging data, while NS-Net segments neurons from the background-removed data. By combining these networks into one framework, DeepWonder achieves a processing speed improvement of nearly ten folds compared to the widely-used CNMF-E technique in widefield calcium imaging analysis. Additionally, DeepWonder improves segmentation and activity inference accuracy, represented by an 11.1% promotion in F1 scores and a 21.5% promotion in temporal correlation scores. DeepWonder is also robust to noise and achieves high accuracy even in low excitation power situations.

1.  Conclusion and Discussions
    1.  Limitations

**Depth**. The depth limitation is resulted from the intrinsic tissue nature of scattering. In our experiments, the depth of neuron that can be resolved is approximately 150 μm. This can be improved if calcium indicators with longer wavelength are developed.

**Sensitivity.** DeepWonder is able to significantly improve the processing speed and accuracy of calcium imaging analysis compared to current techniques, such as CNMF-E. Additionally, the hybrid microscopy device and comparison with two-photon recordings suggest that DeepWonder provides accurate neuronal segmentation and activity inference in mouse recordings, with high precision scores and signal correlations with two-photon ground truth. The results show that DeepWonder has advantages in both speed and performance compared to widely used CNMF-E.

1.  Future work

**Computational microscopy.** The development and implementation of a real-time ultra-large scale imaging at high resolution microscope is a challenging task for most laboratories. However, the advent of new scientific cameras and computational methods has provided low-cost alternatives. In our recent work, we have successfully combined scanning light field microscopy with a low-cost objective to achieve high numerical aperture (NA) imaging in astronomy. Furthermore, we have extended this technique to biological imaging, which has yielded promising results.

**Miniscope with computational imaging.** Another direction is to decrease the size of microscope. We have collaborated with Allipasha’s group to develop a minimized microscope with large FOV to monitor the free-moving animals.

**Biomedical applications.** We have applied mesoscopic imaging to study seizure and anesthesia.
