Real-time Ultra-large-Scale imaging with High-resolution microcopy

Qionghai Dai

Department of Automation, Tsinghua University

# Abstract

# Introduction: requirement and challenge for large scale-imaging

Due to the intricate and constantly changing nature of living systems, predicting systematic behaviors solely from the properties of individual components is often challenging. To investigate the biology of a system, such as neural network activity across cortical regions, leucocyte trafficking dynamics, or tumor metastasis, an appropriate microscope is required, which possesses a field of view (FOV) of at least one millimeter, sub-cellular resolution, and the ability to record biological processes in real-time. Achieving this requires an optical system with high space–bandwidth product (SBP), i.e., a combination of high resolution and FOV, along with an acquisition system that has high data throughput, i.e., a large pixel number and frame rate. Recent advancements in microscopy, such as the Mesolens microscope, have enabled high-resolution imaging with a broad FOV. By utilizing confocal scanning mode, the Mesolens can obtain vast amounts of information from millimeter-scale specimens with optical sectioning capability. For system biology studies, however, dynamic imaging is crucial, and sequential recording schemes can result in limited data throughput. For example, in order to perform brain-wide functional imaging of mammalian cortexes with sub-cellular resolution at video rate (\>10 f.p.s. for calcium responses), an imaging system should have a FOV of approximately 10 mm × 10 mm, a resolution of around 1 μm, and a data throughput of more than 4 gigapixels per second.

![C:\\Users\\weigu\\Documents\\WeChat Files\\xiehao3016\\FileStorage\\Temp\\1678416794279.png](media/7812e3cce218083e68682b1b251376d9.png)

Fig. 1 \| Imaging a large field of view. The physical field of view of different imaging methods (×10 NA 0.4 lens, ×4 NA 0.47 Mesolens and ×8 NA 0.35 RUSH system using 35 camera sensors for image capture), shown relative to the mouse brain.

1.  Challenges for large scale and high resolution

The SBP of microscopes is fundamentally restricted by scale-dependent geometric aberrations of optical systems, leading to a compromise between achievable resolution and FOV. To overcome this limitation, two approaches have been developed: (1) image stitching, in which large samples are imaged in pieces, and (2) Fourier ptychography, in which the specimen is imaged under various illumination conditions with a low-resolution system, and the final image is obtained via Fourier-domain post-processing. Unfortunately, these techniques suffer from low speed and are incapable of supporting single-shot, whole-FOV information acquisition, which is essential for imaging biological dynamics. Additionally, these methods require the samples to remain static during the entire imaging process, making them challenging to apply to in vivo imaging of awake, behaving animals. Furthermore, the need to select small regions of interest (ROIs) for high-speed recording renders their application impossible for large-scale imaging of biological dynamics. Telescopes of non-planar imaging surfaces have been proposed for high-SBP astronomy, successfully addressing the design and manufacturing challenges. However, adapting this strategy from telescopy to microscopy is not straightforward.

-   Data storage and transmission
    1.  Organization of this chapter

This chapter is structured into six sections. The first section serves as an introduction to the topic. The second section presents the Real-time Ultra-large Scale imaging with High resolution microscopy (RUSH) approach, which involves using a customized microscope and a camera array to achieve ultra-large scale and high resolution imaging. The third section describes the attempt to simultaneously monitor neural activity in the superficial cortex and hippocampus. In the fourth section, meso-scale imaging is extended to a curved surface. The fifth and sixth sections introduce algorithms for image denoising and neural detection, respectively. Finally, the limitations and future directions for large-scale imaging are discussed.

.

# Real-time Ultra-large Scale imaging with High resolution microcopy (RUSH)

1.  Principle of RUSH

The customized objective used in the RUSH system was composed of 14 optical elements in 11 groups, and was 161 mm in diameter and 280 mm in length. It was designed to achieve a 10 mm × 12 mm FOV and 0.35 NA over the wavelength range 420–680 nm. The spherical intermediate image was relayed by a 5 × 7 relay lens array and imaged by the sensor array, which was a water-cooled sCMOS sensor with 2,560 × 2,160 pixels and 16-bit depth. The entire optical system had a magnification factor of ×8 and an off-axis and spacing tolerance of \~2 μm. For wide-field fluorescence imaging, a light-emitting diode light source was used for excitation, with a bandpass excitation filter at 470 ± 20 nm and an emission filter at 525 ± 20 nm, chosen based on the fluorescence dyes or proteins used in the imaging. Supplementary Fig. 1 provides more details on the technical specifications and the CAD design and Zemax optical parameters can be found in Supplementary Fig. 2. Supplementary Fig. 8 shows photographs of the whole RUSH system and several major components.

.

![](media/fa085de714e50f9498915b10776e85d2.png)

Fig. 1: Schematic and characterization of a RUSH system. a, Diagram of the RUSH system. In fluorescence imaging mode, the excitation beam from the light source is filtered with an excitation filter and reflected by the dichroic mirror (DM), before it passes through the customized objective and is projected onto biological samples. The fluorescence is collected by the same objective, filtered by the DM and an emission filter, reflected by a mirror (M), and forms a spherical intermediate image. The spherical field is divided into 5 × 7 sub-FOVs and imaged with corresponding collection units composed of the relay lens array and 35 sCMOS cameras. The customized objective lens is designed with 0.35 NA and 10 × 12 mm2 FOV; the collection units provide a data throughput of up to 5.1 gigapixels per second. b, Illustration of the FOV of the RUSH system. Scale bar, 2,000 μm. c, Average FWHM of the 500-nm-diameter fluorescence beads across the whole FOV.

-   Calibration and imaging stitching

The alignment of sub-FOVs is crucial for seamless stitching and requires high-accuracy calibration. However, conventional camera-array calibration techniques fail for RUSH due to its small overlap and shallow depth of field. To overcome this, the authors proposed a fast computation-in-loop calibration approach using spatiotemporal structured illumination to build homographic matrices that map images from 35 cameras to the 10 × 12 mm2 FOV. This approach provides sub-pixel calibration precision and feedback for mounting the camera array. During mounting, the displacement between the captured and expected mappings is calculated, and mounting parameters are fine-tuned accordingly. The proposed approach is computationally efficient and can elegantly address the challenges of assembly and calibration.

![](media/cad2cda4bd197e06b30f9fa901d6c2fb.png)

Supplementary Figure S9: The calibration steps of the local-to-global map table for seamless sub-FOV stitching. STEP 1: We set the global physical coordinates using the temporal-division coding of different cells on a high-density LCD module (\~500 PPI). Specifically, 12-bit temporal codes are used for x and y coordinates, respectively. STEP 2: Each sub-FOV camera captures an image sequence of one specific small LCD region. Then the corresponding global position of each LCD cell can be decoded from its temporal pattern. STEP 3: For each cell in the sub-FOV image, we further extract its precise local image coordinates using centre-of-area method, including binarization and weighted averaging. STEP 4: After retrieving the global and local coordinates of all the sub-FOVs, we build a set of homographic matrices {H\#} for successive stitching.

-   Data transmission and Data storage

We have designed a computer cluster with nine nodes to handle the large amount of data generated by the RUSH system. The data from the 35 cameras were captured synchronously and continuously with a maximum frame rate of 30 frames per second. The data were then transmitted via dual-camera links to optical cables, with a bandwidth of 5.1 gigapixels per second. The system used a distributed file system with 324 hard disks to schedule local data writing requests to each node and to provide cross-node data exchange capability. This facilitated a highly parallel distributed stitching algorithm with adjustable granularity, which allowed real-time online stitching with adaptive resolution adjustment according to the regions of interest. The entire gigapixel video could be stitched and stored offline at up to 1.1 frames per second. A graphical user interface was developed to provide online flexible visualization of the multi-scale data with two high-definition displays.

.

![](media/f3bf7981050672be8a1c6251cea819e6.png)

Supplementary Figure S10 Diagram for the data transmission, storage and image processing. We use a root server to control the cameras, the computing cluster, the user client and other external devices including the synchronizer, light source, 3-axis stage, calibrator, and the monitor. Firstly, 35 cameras are synchronized to capture the subFOV images based on our customized protocol. The high-bandwidth data is then transmitted through a DFS for data processing. Parallel stitching algorithm is conducted based on the calibrated homographic matrices for real-time display. Users can specify the parameters such as exposure time and illumination intensity by the user control client.

1.  Dendritic imaging in cultured cells
-   Cell culture and staining

    R Rat primary cardiomyocytes were isolated from neonatal pups aged between 0 and 3 days, following a protocol that has been previously described with slight modifications (Reference 39). Briefly, the cardiomyocytes were dissociated from freshly isolated ventricular fragments after a series of incubations in digestion buffer consisting of 0.1% trypsin (15090046, GIBCO) and 0.08% type II collagenase (CLS-2, Worthington Biochemical) in Hank’s balanced salt solution (HBSS), which was freshly prepared and pre-warmed to 37 °C with gentle stirring. The isolated primary cells were collected by centrifugation at 1,000 r.p.m. for 5 min, and then pre-plated in a Petri dish with a diameter of 10 cm for 2 h. After pre-plating, the medium was swirled gently and the enriched cardiomyocytes were seeded onto pre-cleaned 18-mm-diameter cover glasses at a density of 2 × 105 cells per cover glass. The cells were then returned to the CO2 incubator for 3 days. Subsequently, the cardiomyocytes were stained with 1 μM Fluo-4 AM (Invitrogen) in HBSS (with Ca2+ and Mg2+) at 37 °C for 30 min, loaded into the imaging chamber at 37 °C with HBSS, and perfused at 0.5 ml min−1 for imaging. The imaging parameters for the data shown in Figure 2a were 8 bits per pixel (b.p.p.) and 30 frames per second (f.p.s.).

    .

    The isolation of primary cortical neurons was carried out following a previously described method with slight modifications. The cerebral cortex was collected from rat pups aged between 0 and 3 days and cortical neurons were dissociated from it through a 0.25% trypsin digestion at 37 °C for 15 min. The isolated cells were then seeded on 18-mm-diameter cover glasses pre-coated with 0.1% poly-D-lysine (Sigma-Aldrich) at a density of 5 × 104 cells per well in 12-well plates. The neurons were cultured in Neurobasal medium supplemented with 2% B-27, 1% GlutaMAX and 1% penicillin–streptomycin (all from GIBCO) for 10 days before staining with 2 μM Fluo-8 AM (AAT Bioquest) in ex-cellular buffer (composed of NaCl 150 mM, KCl 4 mM, MgCl2 2 mM, CaCl2 2 mM, glucose 10 mM and 4-(2-hydroxyethyl)-1-piperazineethanesulfonic acid (HEPES) 10 mM, pH 7.4) at 37 °C for 30 min. The neurons were then stimulated in action buffer (composed of NaCl 60 mM, KCl 90 mM, MgCl2 2 mM, CaCl2 2 mM, glucose 10 mM and HEPES 10 mM, pH 7.4) for 5 min before being perfused in an imaging chamber with ex-cellular buffer at 37 °C for 10 min prior to imaging. The imaging parameters used for Fig. 2e were 16 bits per pixel (b.p.p.) and 5 frames per second (f.p.s.).

-   Imaging results

    In order to demonstrate the efficacy of our RUSH macroscope for large-scale, high-resolution and high-throughput imaging of biological dynamics, we conducted functional imaging of large cell ensembles. While fluorescence imaging of the cardiac cellular network is essential for gaining detailed insights into the cellular processes that are fundamental to cardiac function, it has previously been limited to small fields of view (FOVs) or low resolution23. We cultivated rat primary cardiomyocytes and captured intercellular calcium dynamics at a rate of 30 Hz. Figure 2a presents the spatiotemporal propagation of a calcium wave across the cardiac cell ensemble, with wave phases depicted using different colors that correspond to different temporal delays. Enlarged views of sub-cellular structures are presented in Fig. 2b and c. Furthermore, we show the fluorescence signals (ΔF/F0) of all segmented cells in Fig. 2d, indexed by their wave phases. It can be observed that the calcium signal propagates in a periodically spiral pattern across the entire FOV (Supplementary Video 1). The RUSH system's high throughput allows us to capture non-periodical signal propagation in cardiac ensembles, either within a single cell or among multiple cells (Supplementary Fig. 16 and Supplementary Video 2). However, it is impossible to visualize wave propagation at subcellular resolution with conventional microscopes that have small FOVs.

    Compared to cardiac cellular ensembles, neural ensembles have the ability to form long-range connections. As a result, high-resolution and large-scale functional imaging is necessary to study neural network activity effectively. In this regard, we conducted a proof-of-concept experiment using cultured rat neuron ensembles by performing calcium imaging, which was prepared in a manner similar to the cardiac cells. Figure 2e depicts the spatiotemporal alterations of calcium signals across the neuron ensemble, while Fig. 2f–i illustrate the propagation of calcium signals along dendrites. Our RUSH macroscope enables the recording of fluorescence dynamics in somas and the observation of signal propagation along fine structures, such as single dendrites, as illustrated in Supplementary Video 3..

![](media/887ee31f944f70abedef427e3f672749.jpeg)

Fig. 3: High-throughput calcium imaging of cardiac cellular ensembles and neuron ensembles. a–c, Colour-coded spatiotemporal projection of calcium signals from cultured rat cardiomyocytes (a), with enlarged views shown in b and c. Different colours visualize the peak instants of the calcium signal in one period, and the intensity corresponds to the standard deviation of the fluorescence signal. d, Calcium intensity traces (ΔF/F0) of all segmented cell groups, indexed by their temporal delays. e–g, Colour-coded spatiotemporal projection of the calcium signals from cultured neuron ensembles (e), with enlarged views shown in f and g. Colours and intensities are defined in the same way as in a. h, Maximum intensity projection image of the outlined region in f. i, Fluorescence signals of the numbered regions in h. Scale bars, 1,000 μm (a,e), 100 μm (b,c,f,g), 50 μm (h).

1.  Subcellular imaging in vivo
    -   Transgenic transcription

We performed the craniotomy as described in a previous report41, with a window size of \~8 mm × 8 mm, then installed flat optical windows and cemented the custom-made coverslips (D-shape) and aluminium head posts to the skulls.

For acute imaging, Cx3Cr1-GFP transgenic mice (JAX no. 008451) were head-fixed under the RUSH objective for immediate imaging while keeping the mice warm and anaesthetized (1–1.5% isoflurane). For the data shown in Fig. 4, the imaging parameters were 8 b.p.p. and 5 f.p.s.

For chronic imaging, Thy1-YFP (H line, JAX no. 003782) and Thy1-GCaMP6s (GP4.3, JAX no. 024275) transgenic mice were left for at least 2 weeks after craniotomy for recovery. During imaging, awake mice were placed in a tube with their heads restrained under the objective of the RUSH. During imaging with GP4.3 mice, puffs of compressed air (100 ms duration and 10 s interval) were applied to whiskers on the right through a 1-mm-diameter tube placed ∼10 mm away42.

-   Viral injection

For calcium imaging of dendrites, we sparsely labelled the neurons42 of adult C57BL/6 mice with a mixture of diluted AAV2-9-hSyn-cre and AAV2-9-Ef1a-DIO-GCaMP6f viruses (from BrainVTA Technology). For the data shown in Fig. 5, the imaging parameters were 16 b.p.p. and 14 f.p.s.

![](media/5584cc1807931419128f0d3ebed1aa47.jpeg)

Fig. 6: In vivo brain-wide calcium imaging of adult C57BL/6 mice at dendritic resolution.a, Large-FOV, high-resolution image of the mouse brain cortex. b,d, Enlarged views of the areas labelled in a. The contours of the segmented neuron cells are labelled. c,e, Temporal traces of the segmented cells labelled in b and d, respectively. f, Enlarged view (s.d. projection) showing the clear structures of dendrites, highlighted with semi-automatic tracing of neurons. g, The same enlarged view with labelled ROIs. Each colour encodes an individual neuron. h, Temporal traces of the ROIs labelled in g. Scale bars, 1,000 μm (a), 100 μm (b,d), 50 μm (f,g).

-   Imaging results

To showcase the proficiency of the RUSH macroscope in large-scale, high-resolution, and high-throughput imaging of biological dynamics, we performed calcium imaging of neurons and dendrites in awake mice in vivo. In this study, we utilized both virus-infected adult C57BL/6 mice and Thy1-GCaMP6s transgenic mice. Calcium dynamics were recorded at 14 f.p.s., and the results are presented in Fig. 6, Supplementary Figs. 20 and 21, and Supplementary Video 8. Our experiments enabled us to record calcium signals from neural somas (Fig. 6b–e), as well as to observe calcium propagation along dendrites (Fig. 6f–h). These investigations can provide the multi-scale data necessary for studying brain-wide correlations among neuron responses, including the response delay of calcium signals at different branches of a single neuron.

.

# Form flat imaging to multi-planar imaging

1.  Why we need multi-focal imaging

Recent research has shown that many cognitive processes involve the interaction of multiple brain regions. For instance, the formation of episodic memory is dependent on the interplay between the hippocampus and prefrontal cortex [1-3], while spatial navigation is dominated by hippocampal-parietal cortical interactions [4-7]. Similarly, posttraumatic stress disorder (PTSD) is associated with the amygdala, medial prefrontal cortex, and hippocampus [8]. These nuclei are located more than 1 millimeter beneath the dura in adult mice and are spread across the whole brain. To investigate the dynamic behavior of different brain modules at a fine scale, it is essential to have an optical system with cellular resolution, brain-wide field of view, video-rate acquisition, and multi-depth imaging capabilities.

Various techniques have been proposed to achieve deep mouse brain imaging. Optical fiber photometry and gradient index (GRIN) lenses are advantageous in enabling deep brain imaging. However, optical fiber photometry lacks spatial resolution, as it collects the signal of a bulk of neurons [9, 10]. GRIN lens endomicroscopes can reach depths of several millimeters but have a limited field-of-view of only several hundred microns, which cannot image the entire mouse brain [11]. Multi-photon microscopy (MPM) has the potential to image at a depth of 1 mm with diffraction-limited resolution [12]. However, the repetition frequency, field-of-view, and imaging speed are limited, and are interdependent. Several methods have been proposed to enhance the volumetric imaging speed while maintaining the field-of-view, such as dual-plane imaging by remote focusing [13], random-access scanning [14], reverberation two-photon microscopy [15], and spatial light modulator (SLM) combined with MPM [16]. However, these techniques are limited by a field-of-view of only 1 mm2, which is not sufficient for simultaneous observation of large areas encompassing multiple cortical areas. The 2-photon random access mesoscope (2p-RAM) [17] provides diffraction-limited resolution in a cylindrical volume (ϕ5 mm ×1 mm), but its frame rate is only 1.9 Hz for a 4.4 mm ×4.2 mm field-of-view, limiting its use in dynamic imaging.

Several imaging systems and techniques have been proposed for whole mouse brain imaging with large FOV, including the Mesolens and the RUSH macroscope. However, these systems have limitations, such as slow imaging speed, point-scanning strategy, and scattering in tissue that can preclude high-quality imaging of certain brain regions. Additionally, there is currently no imaging system or technique that can achieve simultaneous imaging of the cortex and hippocampus with cellular resolution, brain-wide FOV, and video-rate acquisition. Therefore, there is a need for further development of imaging systems and techniques to enable comprehensive investigation of the interactions between different brain regions involved in various cognitive processes.

In order to address the challenge of simultaneous recording of the cortex and hippocampus dynamics with cellular resolution, we propose a microscopic system that comprises of multiple steps. Firstly, a customized optical window is implanted above the mouse brain, which involves removing the skin, skull, and some white matter above the region of interest in order to eliminate scattering. Additionally, an extra glass column is inserted above the hippocampus to shift its surface to the superficial plane. Secondly, a wide-field fluorescence mesoscope is built using off-the-shelf optical components, which is compatible with various mesoscopic systems. Finally, we demonstrate the effectiveness of our proposed technique in imaging the cellular structures of microglia, neurons, and vasculature dynamics in mouse cortex and hippocampus simultaneously.

1.  Simultaneous imaging of cortical and subcortical nucleus
    -   Optical design

Fig. 1(a) and Fig. 1(b) show the principle of simultaneous multi-planar imaging. First, the skull of the mice is removed, and a part of cortical matter is ablated to expose the hippocampus. The surface of the hippocampus is about 1 millimeter below the dura, while the layer 2/3 neurons in the cortex are about 100\~300 μm below the dura. To shift the neurons in the hippocampus to the superficial cortex, media with a higher refractive index is inserted above the hippocampus. The apparent depth Ha in refractive media is related to the real depth Hr according to Snell’s Law, where ni is the refractive index of the imaging plane and no is the refractive index of the refractive media. To compensate for the depth difference, the height of the media that needs to be inserted is calculated as Hm = (no - ni) \* Hr / ni. Assuming a dry objective is used for detection at a wavelength of around 515 nm, the refractive indices are estimated as ni = 1 and no = 1.5. The depth between the hippocampus and superficial cortex is about 0.9 mm, and the thickness of the coverslip is 0.17 mm. Therefore, a customized optical window is designed for multi-planar imaging. A 0.9-mm-height and 2-mm-diameter glass column is stuck to the bottom of the cover glass at the position of the mouse hippocampus, and a second glass column with an optimal thickness of 1.8 mm is placed on the top to further compensate for the depth difference.![](media/bb70ea3284ecf2c033a17cd4adfabd0d.png).

Fig. 1. The principle of the proposed multi-plane imaging. (a) Schematic of the experimental setup showing the chronic window implanted above the dentate gyrus. (b) Schematic diagram of the proposed multi-planar imaging. (c) The scheme of the custom-built wide-field mesoscope, with brain-wide FOV and cellular resolution.

-   Surgery

    During the chronic craniotomy procedure, a 6 mm diameter window was created, and the cortex matter was aspirated using a 0.9 mm diameter blunt needle connected to a vacuum pump. The central position of the ablated cortex was located approximately 1.5 mm from the sagittal suture and 2 mm from the lambdoid suture. Once the cortex matter was aspirated, a chronic window was assembled by adhering a ϕ9 mm glass coverslip to a glass column using tissue adhesive. The window was then implanted above the mouse cortex, and an aluminum head post was mounted to the skull and fixed with dental cement. During the surgery, the mouse was anesthetized with isoflurane, and a breathing frequency of 1 Hz was maintained. Body temperature was kept at 37.5 ℃, and eye ointment was applied. The mouse was allowed to recover for two weeks before chronic imaging experiments were performed. The mouse was alive for more than two months after being implanted with the chronic window..

    -   Imaging results

        We have demonstrated the capability of our system to perform in-vivo multi-planar neuron imaging in Thy1-YFP mice (JAX No. 003782). The entire mouse brain was imaged using the RUSH microscope, as depicted in Fig. 4(a). The hippocampus and cortex were labeled in Fig. 4(a) and subsequently imaged in Fig. 4(b) and (c), where a number of spine-like structures were clearly distinguished and marked with yellow circles. Additionally, the axons were distinguishable in both subregions, indicated by red arrows, thus highlighting the superior performance of our system. The lateral resolution of our customized microscope, as illustrated in Fig. 5(a), was found to be approximately 3.25 μm, which was restricted by the pixel size of the sCMOS detector. Consequently, only the soma could be visualized in each subregion (Fig. 5(b) and (c)), with a significantly lower signal-to-background ratio. Our results collectively demonstrate that our system has the potential to be employed for in-vivo calcium imaging with cellular resolution.

        To assess the viability of our technology for chronic mouse imaging, we allowed a recovery period of two weeks following optical window implantation. In Fig. 7(a1)-7(a3), we present brain images of Thy1-YFP mice captured on Day 14, 30, and 60 post-implantation. Neurons in all regions, including the hippocampus in Fig. 7(b1)-(b3) and superficial cortex in Fig. 7(c1)-(c3), are visible, indicating that our microwindow implantation approach is suitable for chronic imaging. Fig. 7(a1)-(c1) and Fig. 7(a3)-(c3) were captured using the customized-built wide-field fluorescence mesoscope, whereas Fig. 7(a2)-(c2) were captured using the RUSH macroscope. The post-surgery behaviors of the mice (n≥3) were evaluated, and no discernible abnormalities were observed.

        .

        ![](media/f23401872d75916e547c9c925d41df6b.png)

        Fig. 8. In vivo chronic imaging of the mouse brain (14, 30 and 60 days post craniotomy). (a1-a3) Large-FOV, high-resolution neuron images of the mouse brain. Scale bar: 1 mm. (b1-b3) Magnified views of the hippocampal regions. (c1-c3) Magnified views of the superficial cortical region. Scale bar 100 μm.

    1.  **Spinning-disk Multi-planar imaging on Arbitrarily-shaped surface Technique**

        We have designed and constructed a novel wide-field fluorescence microscope called the Spinning-disk Mesoscopic ARbitrarily-shaped-surface imaging Technique (SMART). This microscope has the ability to image on non-planar surfaces while maintaining high spatial resolution across a large field of view. To achieve this, we have developed an active imaging framework that includes automatic detection of the surface profile, active control of illumination, high-speed spinning-disk scanning, and multiplexed detection. The use of a spinning disk and high-speed cameras, similar to the RUSH system and micro-camera array microscope, provides SMART with high optical throughput, enabling it to scan 16.8 voxels per second, which is 100 times faster than previous techniques. This allows for continuous adjustment of the focal depth over a maximum range of approximately 2 mm and at a maximum speed of 140 frames per second.

        Our experimental results demonstrate that SMART microscopy is capable of imaging neural activity and neutrophil migration across the intact superficial cortex of mice, as well as other dynamic processes on complex surfaces. SMART microscopy provides reliable biological images without introducing artifacts and is flexible in terms of its applicability to different systems and imaging conditions. Additionally, the cost-effective nature of the implementation of SMART makes it a useful tool for many areas of biological research.

    -   Optical design

        The operation of SMART is based on a combination of computer vision and optical design, enabling high-resolution imaging of dynamic processes on arbitrarily-shaped surfaces. The imaging process begins with the estimation of surface profiles, which is used to design a spatial-temporal selective illumination sequence. This sequence is then applied to the sample, while the spinning disk is used for fast axial scanning within a single frame exposure time. This allows for the acquisition of surface features with depth encoding. The obtained images, along with the illumination sequence, are then processed to decode cellular information with high accuracy. Overall, this approach provides an effective means for achieving high-resolution imaging of dynamics on complex surfaces.

        To address the resolution-depth of field trade-off in SMART microscopy, we implemented a technique in which the focal length is scanned in a single exposure time. To achieve fast and continuous focus shifting, we utilized a spinning disk, which is typically challenging in mesoscopic systems. To enable high-resolution imaging with a large field of view during disk rotation, we replaced traditional lenses with flat optics to change the position of the focal plane. The spinning disk, composed of glasses with varying thicknesses, was positioned between the two surfaces to produce a focus shift, similar to the "broken pencil illusion" in physics. The use of flat optical elements ensures that all regions of the field of view are treated equally, allowing for high-resolution focal length changes across the entire field of view.

        To address technical limitations in data transfer speed, we utilized a temporal multiplexing detection method in our imaging approach. Specifically, we employed a digital micromirror device (DMD) to modulate the spatiotemporal illumination of the sample, resulting in brightness only in regions where features were in focus. Additionally, the rotation of the spinning disk was tracked by an infrared detector and recorded by a data acquisition device (DAQ), which was synchronized with the DMD and camera. Through the integration of these innovative techniques, we have successfully overcome technical challenges and achieved high-quality, high-resolution imaging of dynamic processes occurring on complex surfaces.

        The illumination patterns were then used to modulate the illumination of the sample through the DMD, which enabled the bright regions to correspond to in-focus areas. The spinning disk was synchronized with the DMD and camera, and the acquisition of images was done in a single frame exposure time. The captured images were then processed to decode cellular information with high accuracy. The axial positions of the surface were also extracted from the illumination patterns and used to reconstruct the surface profile. This approach allows for continuous tuning of the focal depth over a maximum range of \~2 mm and a maximum speed of 140 fps, enabling high-resolution imaging of dynamics on complex surfaces in real time.

        ![](media/0351af84a3f4c2be9f3cc54488e5e5ca.png)

        Figure 1. Schematic diagram of the system. a. Centre, the SMART system consists of two parts, selective illumination and focal modulation. The selective illumination part consists of a digital micro-mirror device (DMD) conjugated to the image plane, which modulates the illumination patterns from the light source. The focal modulation part is a spinning disk with some coverglass of different thicknesses, which shifts the focal image to different depths.

    -   Imaging results

        This ability to image the entire superficial brain allowed us to study the spatiotemporal dynamics of neural activity across a large field of view, which is important for understanding the mechanisms underlying brain function. We were able to detect calcium signals from neurons across the mouse cortex in response to visual stimulation, as shown in Figure 2d and Supplementary Video 2. This demonstrates the ability of SMART microscopy to provide high-quality, high-resolution images of neural activity in vivo, which is essential for advancing our understanding of brain function and disease.

        The SMART microscopy approach enabled the acquisition of high-resolution images of neural activity with a large field of view and high imaging speed. This allowed for the detection of fast, micrometer-resolution spontaneous activity over the superficial dorsal cortex of the mouse brain, which was difficult to achieve with existing wide-field techniques. By using morphological methods, the time series of images at each depth were used to detect the three-dimensional positions of neurons. A polynomial function was then applied to fit the surface, as shown in the inset of Figure 3a. The resulting images and surface profile provided a comprehensive view of the neural activity across the superficial layer of the cortex.

        SMART's ability to capture an image of the entire superficial cortex in one snapshot and identify thousands of neurons with high resolution and efficiency represents a significant advance over existing wide-field techniques. By detecting 5,400 neurons using the CNMF-E algorithm, SMART was able to evenly distribute neurons across the entire field of view, outperforming a conventional microscope with 0.3 NA that could only detect 1,000 neurons within its depth of field. Additionally, by zooming in on four selected regions in detail, SMART was able to reveal the contours of all somata at high resolution, achieving single-cell resolution that surpasses the COSMOS microscope. While the imaging speed of SMART was currently limited by the sCMOS camera speed of up to 50 frames per second, setting the speed to 10 Hz allowed it to match the dynamics of the calcium indicator.

        .

        ![](media/b6734897eec574e426a407b32938b6ec.png)

        ![](media/3906b698f9c9c2e49906c8b30c9ab52c.png)

        Figure 3. Cortex-wide neural imaging of a transgenic mouse. a. Top left, standard derivation of neural activity from our SMART microscopy (scale bar, 1mm), with four zoom-ins across the FOV are displayed on the right (scale bar, 100 μm). The image is registered to the Allen Mouse Brain Common Coordinate Framework. b. Traces of the 5400 neurons.

# Denoising

Fluorescence imaging is photon limited, which means that it is usually not possible to collect enough fluorescent photons to obtain a satisfactory imaging signal-to-noise ratio (SNR). The problem of low imaging sensitivity is the fundamental challenge of fluorescence imaging. Considering the whole process of fluorescence labeling, excitation, and detection, the causes of the photon-limited challenge can be summarized into four aspects (**Fig. 1**). First, the low quantum yield (*i.e.*, the percentage of photons absorbed by the fluorophore that is converted to fluorescent photons) of fluorescent indicators and their low concentration in labeled cells lead to the short of fluorescent photons at the source. Second, although using higher excitation power can directly increase the number of fluorescent photons (*e.g.*, single-photon fluorescence increases linearly with excitation power, while two- and three-photon fluorescence increases squarely and cubically, respectively), fragile living systems cannot tolerate high excitation power for a long time. Many experiments have shown that light-induced photobleaching, phototoxicity, and tissue thermal damage will disturb normal cellular physiological processes, such as cell proliferation, cell migration, vesicle release, action potential firing, *etc*. Enhancing imaging SNR by increasing the excitation power is not feasible in practical imaging experiments. Third, observation of high-speed dynamic life activities requires high imaging speed. At a certain number of fluorescent photons emitted by the sample per unit period of time, the higher the imaging frame rate, the shorter the exposure time of each image frame, and the fewer fluorescent photons can be collected. Therefore, high-speed imaging further exacerbates the shortage of fluorescent photons. The last and the most essential reason is the quantum nature of light makes the randomness of optical measurements inevitable. The number of photons detected by even the most sophisticated photodetector can only be a Poisson random number of the actual number of photons. The detection noise due to the quantum nature of light is called photon shot noise. In fluorescence imaging, detection noise dominated by photon noise exacerbates the measurement uncertainty, hinders visualization of the structure and function of living organisms, and can even mislead qualitative and quantitative descriptions of biological mechanisms.

![](media/f53697e780e7081a7d000d7e92a6d7c6.png)

Fig. 1 \| The causes of the photon-limited challenge in fluorescence imaging, involving multiple aspects of biophysics, biochemistry, and physical optics.

The inherent photon shot noise is the essential cause of the low imaging sensitivity and is also one of the most fundamental and formidable challenges in fluorescence imaging. Fundamentally, all measurement processes obey the laws of quantum mechanics, and the most direct manifestation is the existence of an upper limit on the sensitivity of any measurement. The sensitivity limit of optical measurements in classical physics is known as the photon noise limit (or the well-known standard quantum limit). Fluorescence imaging is a branch of optical measurement technology, and any imaging system based on classical physics is bound to obtain images that are at least Poisson random samples of the actual photon distribution. In theory, the shot-noise limit specifies an upper bound on the imaging SNR. In practice, the inherent photon noise increases measurement uncertainty, degrades image quality, and limits all aspects of imaging performance such as resolution, speed, and depth. Actually, not only fluorescence imaging but any other precision optical measurement is plagued by noise. Photon shot noise is an inescapable obstacle in cutting-edge scientific observations. *Nature*, one of the most famous international academic journals, published a technical comment in 2021 with a topic of "A shout-out for noise-reduction tools", pointing out that any experimentally measured image contains noise, and calling for the development of more accurate, reliable, and efficient noise suppression tool to facilitate fundamental scientific research.

The information obtained by fluorescence imaging is organized in the form of images, so a natural idea to improve imaging sensitivity is to remove noise in fluorescence images by post-processing, which further reduce the negative impact of noise on downstream analysis. Intelligent image processing methods based on deep learning are the most widely used and best performing solution for image denoising. Using deep learning to restore fluorescence images can compensate for the innate deficiencies of imaging systems and effectively improve microscopic image quality. The application of deep learning consists of two steps. Firstly, data is collected to make a training set, and deep neural networks are trained on the dataset using back-propagation and gradient descent algorithms. Then pre-trained models are deployed and used to process unseen data. Those well-trained models still maintain good generalization on new test data. Such s data-driven paradigm dictates the strong data-dependent nature of deep-learning-based methods, where the dataset has a much greater impact on the performance than the network architecture. Thus, making a representative and category-balanced dataset is crucial for these methods. If a certain class of data is missing in the training set, the network would lose the ability to process such kind of data. Forced processing will often lead to wrong results.

Conventional deep-learning-based denoising methods for fluorescence imaging are based on supervised learning, which means that the training of the deep neural network relies on the supervision of paired ground-truth images (*i.e.*, clean images without noise contamination or high-SNR images with the same underlying scene as the low-SNR images). For static samples, it is not difficult to obtain the ground-truth images by extending the exposure time of the camera or taking many consecutive frames and then calculating the average value of them. So supervised denoising methods are mainly feasible for static or very slowly changing samples. However, biological phenomena are often highly dynamic, non-repetitive activities where the same scene cannot be captured twice, and schemes to obtain training truth values by extending the exposure time or averaging multiple frames are no longer feasible. The heavy reliance on training truth is the most important drawback of conventional supervised methods, but the lack of ground-truth images is very common in fluorescence imaging of living organisms, such as neural calcium imaging, membrane voltage imaging, cell interaction, organelle dynamics, immune response, hemodynamic processes, *etc*. There is an urgent demand to develop new denoising methods to break the dependence of supervised denoising on truth values.

We proposed a self-supervised framework for fluorescence imaging denoising named DeepCAD, which can be used to train denoising models without requiring any ground-truth images and can achieve performance as good as the latest supervised denoising methods. The principle of DeepCAD is shown in **Fig.2**. The original low-SNR image stack acquired by the imaging system is split into two sub-sequences (*xy-t* image sequences) of odd and even frames, which are used as the input and target of the deep neural network, respectively. Then, the neural network is trained with stochastic gradient descent. In brief, traditional supervised learning methods use ground-truth images as the supervised data, while DeepCAD uses adjacent frames of the input noisy images as the supervised data. Although the supervised data also contains the same kind of noise as the input data, the network parameters can still converge to values similar to those trained by supervised learning. The proposed DeepCAD was inspired by Noise2Noise. The training mechanism can be explained as follows: noisy target images produce noisy gradients, but the angle between them and the true gradient is still acute (pointing to similar directions). Also, the disturbance of noise can be eliminated after averaging a large number of noisy gradients over the whole training set. Therefore, the final convergence direction of the network is not affected. After training, the parameters of the pre-trained denoised network will be stored in a model file. When new low-SNR data arrives, a three-dimensional (xy-t) window will traverse the whole video and input these data blocks into the pre-trained model. The output of the model is corresponding denoised blocks, and the complete denoised results will be obtained after stitching these output blocks together.

![](media/e96fd34b3d70d7bdb0c3e2489f59b224.png)

Fig. 2 \| **a**, The self-supervised training strategy of DeepCAD. **b**, The deployment of pre-trained models.

We first captured the spontaneous calcium activity of densely distributed neurites in the first layer of the mouse cerebral cortex using a two-photon microscope. The noise in the original low-SNR images is so severe that it almost drowns out the true signal and the morphology and distribution of dendrites and axons were difficult to recognize (**Fig. 3a**). After denoising with DeepCAD, those imperceptible fluorescence signals in the original low SNR data can be effectively restored (**Fig. 3b**). The SNR of the denoised image exceeds that of the high-SNR image with 10-fold fluorescence photons (**Fig. 3c**), allowing the structure of dendrites and axons to be accurately identified from a single frame. Then, we randomly selected 40 pixels located on the neurites and extracted the fluorescence traces of these pixels, normalized and visualized them in **Fig. 3d**. After comparing with the corresponding high-SNR data, it can be found that the denoised data can resolve the calcium activity of neurons faithfully. Similarly, we performed calcium imaging data of large neuronal populations in Layer 2/3 of the mouse cerebral cortex. The original low-SNR images and denoised images are shown in **Fig. 3e** and **3f**, respectively. The corresponding high-SNR data with 10-fold photons is shown in **Fig. 3g**. With the powerful denoising capability of DeepCAD, the fluorescence signal severely disturbed by noise can be recovered. In the denoised image, the structure of neuronal cytoplasm and fibers becomes clearly visible. The spatial distribution and firing state of most neurons can be recognized from a single frame. Magnified views of red-boxed regions are shown at the bottom of each image, which shows that the fluorescence dynamics of different neuronal structures are also effectively recovered.

![](media/3cf86dee4669b8bed3d6a364ae7f0a73.png)

Fig. 3 \| **a-c**, The denoising performance of DeepCAD on densely distributed axons and dendrites. Scale bar, 100 μm. **d**, Fluorescence traces extracted from 40 dendritic pixels. **e-g**, The denoising performance of DeepCAD on large neuronal populations. Scale bar, 100 μm.

Furthermore, to meet the growing demand of large-scale image processing and real-time high-sensitivity observation, we comprehensively optimized DeepCAD to improve its processing speed and performance. We also designed a multithreaded processing pipeline, as well as an optimal hardware deployment scheme, to integrate the proposed denoising into the imaging system. We finally implemented real-time noise suppression on a two-photon fluorescence microscope for high-sensitivity imaging. With this high-sensitivity imaging technique, we observed various biological events, including neural calcium activity in multiple model organisms (*Drosophila*, zebrafish， and mice), the 3D migration of immune cells after acute brain injury, and the 3D dynamics of adenosine triphosphate (ATP) release in the mouse cortex after laser-induced injury. The implementation of real-time high-sensitivity fluorescence imaging will help biologists solve the photon-limited challenge in fluorescence imaging and facilitate the revelation of underlying biological mechanisms in a wide range of applications.

![](media/01ebd048213b6b34147f5ef080f02a94.png)

Fig. 3 \| **a**, DeepCAD-RT reveals the 3D migration of neutrophils *in vivo* after acute brain injury. Scale bar, 50 μm. **b**, DeepCAD-RT reveals the ATP (adenosine 5’-triphosphate) dynamics of astrocytes in 3D after laser-induced brain injury. Scale bar, 50 μm.

# Rapid calcium signal extraction

The use of widefield microscopy has enabled the imaging of multi-millimeter fields of view and thousands of neurons in mammalian brains at a video rate. However, extracting neuronal activity signals from calcium imaging data at a cellular resolution has been a challenge due to the contamination by tissue scattering and background signals, which makes it time-consuming and difficult to accomplish. To address this issue, we propose a deep learning approach called DeepWonder, which is fueled by simulated calcium recordings but effectively works on experimental data. The proposed method achieves an order of magnitude faster processing speed and improved inference accuracy compared to traditional approaches. The DeepWonder algorithm demonstrated a significant improvement in the signal-to-background ratio, achieving a fifty-fold enhancement when processing terabytes-scale cortex-wide recordings. In just 17 hours using workstation-grade computing resources, DeepWonder extracted over 14,000 neurons, which is an impressive feat compared to the nearly week-long processing time with previous methods. This new approach can serve as a guideline for massive data processing in widefield neuronal imaging, circumventing the need for numerous computational resources.

In this study, we introduce a fast and efficient technique for extracting and demixing neurons from widefield microscope data using deep learning. To overcome the challenge of the lack of training data, we used a simulation of brain tissue to generate optical system-specific paired virtual recordings with and without background. By training a neural network to separate neuronal signals from scattered background, we were able to quickly segment neurons and retrieve spatial footprints and temporal signals using a lightweight convolutional neural network. This technique, which we refer to as DeepWonder, demonstrated nearly tenfold processing speed improvement compared to the widely used CNMF-E algorithm, as validated using both simulation and experimental data. We also verified the accuracy of background removal and segmentation using TPLSM recordings and deployed DeepWonder on several widefield calcium recording systems. Finally, we made our method easily accessible and reproducible by packaging it into a python package and distributing it on an online platform.

The effectiveness of widefield microscope in detecting neurons is limited by background contamination, which hinders signal extraction and detection quality. In DeepWonder, we use a neural network to map images with background contamination to background-free data by generating synthetic widefield calcium imaging data. We create synthetic data by modeling vessels, neurons, and background dendrites and axons based on a specific widefield microscope model to produce realistic virtual recordings with accurate pixel, ΔF/F, and spatial frequency distributions. Paired virtual recordings are fed to the removing background network (RB-Net) to learn the mapping between contaminated and background-free captures. Trained RB-Net learns interpretable features and outputs high-contrast images and vivid neuronal activities without contaminations. DeepWonder enhances correlation scores to the ground truth signals and signal-to-background ratios significantly compared to raw data. RB-Net-driven by virtual data in DeepWonder is effectively applied to remove backgrounds of real recordings. The RB-Net achieves superior performance in SBR, correlation score, and neuron finding scores compared to other state-of-the-art background removal methods while spending almost 7-fold shorter time in removing background. The similarity between virtual generations and real recordings guarantees the high effectiveness of RB-Net in real recordings. We illustrate an SBR improvement in real recordings by RB-Net compared to raw data across 1543 neurons.

NS-Net, the neuron segmentation network proposed in DeepWonder, is designed to segment neurons from background removed data. The NS-Net employs a lightweight CNN that segments neurons from the output of the RB-Net at high speed. The network then semantically segments roughly isolated neurons based on their spatio-temporal connectivity and yields mostly exclusive segmentations. This approach enables the direct readout of the temporal activities of individual neurons since there is no inter-neuron crosstalk. Neurons that are tiled and overlapped are further demixed by a local nonnegative matrix factorization (NMF) algorithm, which eliminates activity crosstalk. NS-Net reliably demixes neurons as close as 0.3 of the neuron diameter, resulting in a temporal similarity of over 0.9 and a spatial similarity of over 0.85.

In terms of performance, NS-Net outperforms state-of-the-art two-photon segmentation techniques CNMF and SUNS with the highest sensitivity and F1 score (0.933 and 0.917, respectively) in the background removed dataset. The processing speed of NS-Net is also 5 times faster than CNMF and comparable to SUNS.

DeepWonder is a framework for analyzing widefield calcium imaging data that achieves a significant improvement in processing speed and accuracy over existing techniques. The framework consists of two neural networks: the Removing Background Network (RB-Net) and the Neuron Segmentation Network (NS-Net). RB-Net removes background contaminations from the imaging data, while NS-Net segments neurons from the background-removed data. By combining these networks into one framework, DeepWonder achieves a processing speed improvement of nearly ten folds compared to the widely-used CNMF-E technique in widefield calcium imaging analysis. Additionally, DeepWonder improves segmentation and activity inference accuracy, represented by an 11.1% promotion in F1 scores and a 21.5% promotion in temporal correlation scores. DeepWonder is also robust to noise and achieves high accuracy even in low excitation power situations.

![](media/e45d6c10728cd90f4a53ad1d2f82a695.png)

Principle of deep widefield calcium finder (DeepWonder). a. Training stage of removing background network (RB-Net) in DeepWonder. Based on specific widefield microscope parameters (numerical aperture, objective focal length, and magnifications) and imaging parameters (wavelength, imaging depths, and imaging power), we firstly use the proposed realistic widefield simulator to generate virtual captures with high similarity with experimental captures as inputs. Meanwhile, we can generate the capture with the same neuron distributions but without background contaminations as labels. We feed both inputs and labels to train the removing background network (RB-Net) such that it can restore background-free neuronal images from background-contaminated images. b. DeepWonder works on new recordings. After the network is trained, it can be used to remove the background of experimental captures. We further apply a neuron segmentation network (NS-Net) to segment neurons and extract neuronal signals from the background-removed movies (Supplementary Fig. 1, 2).

# Conclusion and discussions

1.  Limitation of single-photon method
-   Depth

The depth limitation is resulted from the intrinsic tissue nature of scattering. In our experiments, the depth of neuron that can be resolved is approximately 150 μm. This can be improved if calcium indicators with longer wavelength are developed.

-   Sensitivity

That's impressive! It seems like DeepWonder is able to significantly improve the processing speed and accuracy of calcium imaging analysis compared to current techniques, such as CNMF-E. Additionally, the hybrid microscopy device and comparison with two-photon recordings suggest that DeepWonder provides accurate neuronal segmentation and activity inference in mouse recordings, with high precision scores and signal correlations with two-photon ground truth. The results show that DeepWonder has advantages in both speed and performance compared to widely used CNMF-E.

![](media/01da360146b4bc54784dd6c04dc573d4.png)

DeepWonder achieves accurate neuron segmentation and activity inference validated by two-photon (2p) microscope.

a. The hybrid 1p–2p microscope setup. LED, light-emitting diode light source; Ti:Sa, titanium:sapphire laser; EOM, electro-optical modulator; M, mirror; DM, dichroic mirror; BS, beam splitter; Fm, emission filter; Fx, excitation filter; CL, collection lens; TL, tube lens; S, triggerable shutter; CAM, sCMOS (scientific complementary metal-oxide semiconductor) camera; PMT, photomultiplier tube; Obj, objective. Right box: control signals of the shutter, LED, EOM, and camera exposure, where high-level signals are activated and low-level signals are deactivated. b. Maximum intensity projection (MIP) of widefield (top), RB-Net processed widefield movie (middle), and two-photon movie (bottom). Triangles mark neurons and the corresponding temporal activities are plotted on the right side. c. Zoom-in plots of temporal activities of neuron No. 14, 16, and 17 in the widefield raw movie (green), RB-Net de-background movie (red), and 2p movie (blue.) d. Temporal correlations of 27 picked neurons with 2p by RB-Net are significantly increased compared to the raw movie (p\<0.001, two-sided Wilcoxon signed-rank test). e. DeepWonder (left) and CNMF-E segmentation results (right). Blue masks represent corrected segmentations, green masks represented missed segmentations by current methods, and pink masks represent false segmentations by current methods. The precision, sensitivity, and F1 score of DeepWonder are 0.94, 0.88, and 0.91, while for CNMF-E are 0.56, 0.96, and 0.73. f. Correlations of DeepWonder neuron activities with 2p across 5 animals and 20 datasets. g. Precision score of DeepWonder segmented neurons with 2p dataset as the reference across 5 animals and 20 datasets reaches 0.88 ± 0.05 (mean ± std). h.F1 score of DeepWonder (red, 0.88 ± 0.04, mean ± std) and CNMF-E (blue, 0.73 ± 0.13, mean ± std) across all datasets. DeepWonder significantly outperforms CNMF-E in F1 score (p\<0.001, two-sided Wilcoxon signed-rank test). i. Temporal correlation of DeepWonder (red, 0.83 ± 0.14, median ± median absolute deviation) and CNMF-E (0.79 ± 0.22, median ± median absolute deviation) with 2p across all datasets (n = 1570 neurons). DeepWonder significantly outperforms CNMF-E in temporal correlations with 2p (p\<0.001, two-sided Wilcoxon signed-rank test)

1.  Future development
    -   Computational microscopy

The development and implementation of a real-time ultra-large scale imaging at high resolution microscope is a challenging task for most laboratories. However, the advent of new scientific cameras and computational methods has provided low-cost alternatives. In our recent work, we have successfully combined scanning light field microscopy with a low-cost objective to achieve high numerical aperture (NA) imaging in astronomy. Furthermore, we have extended this technique to biological imaging, which has yielded promising results.

-   Miniscope with computational imaging

Another direction is to decrease the size of microscope. We have collaborated with Allipasha’s group to develop a minimized microscope with large FOV to monitor the free-moving animals.

-   Biomedical applications
